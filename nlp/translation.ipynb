{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda0fc55-dc2c-4ede-ae72-78db2534eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "\n",
    "\n",
    "import unidecode\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea2aeb-f243-4ae0-a94d-86787dc36c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7843f4c5-6d48-4d6e-9193-de470a065d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor(X, title=''):\n",
    "    plt.imshow(X.detach().numpy())\n",
    "    plt.title(f'{title} {X.shape}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8b0c5d-98c2-4f7b-ae54-5ee52ec1fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole: 232736\n",
      "Only short (<=7): 155267\n"
     ]
    }
   ],
   "source": [
    "SENT_LENGTH = 7\n",
    "\n",
    "def tokenize(s):\n",
    "    words = re.split(r'\\W+', s.strip())\n",
    "    while not words[-1]:\n",
    "        words.pop()\n",
    "    return words\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/fra.txt', sep='\\t', names=['eng', 'fra', 'license'])\n",
    "df.drop(columns=['license'], inplace=True)\n",
    "\n",
    "exclude_chars = r'[^a-z ]'\n",
    "df['fra_ascii'] = df['fra'].map(unidecode.unidecode).map(str.lower)\n",
    "df['fra_ascii'] = df['fra_ascii'].map(lambda s: re.sub(exclude_chars, '', s))\n",
    "df['eng_ascii'] = df['eng'].map(unidecode.unidecode).map(str.lower)\n",
    "df['eng_ascii'] = df['eng_ascii'].map(lambda s: re.sub(exclude_chars, '', s))\n",
    "df['eng_list'] = df['eng_ascii'].map(tokenize)\n",
    "df['fra_list'] = df['fra_ascii'].map(tokenize)\n",
    "\n",
    "print('Whole:', len(df))\n",
    "\n",
    "df = df[(df['fra_list'].map(len) <= SENT_LENGTH) & (df['eng_list'].map(len) <= SENT_LENGTH)]\n",
    "print(f'Only short (<={SENT_LENGTH}):', len(df))\n",
    "\n",
    "# Most common words filter\n",
    "#most_common_eng = [r[0] for r in eng_words.most_common(10)]\n",
    "#df = df[df['eng_ascii'].str.contains('|'.join(most_common_eng))]\n",
    "\n",
    "SENT_LENGTH += 1  # add room for SOS and EOS tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e19d0d-13f4-4126-b4c7-264ec6a3f503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(fra_dict)=24420\n",
      "len(eng_dict)=12539\n"
     ]
    }
   ],
   "source": [
    "EOS_token = 0\n",
    "SOS_token = 1\n",
    "\n",
    "special_tokens = ['<EOS>', '<SOS>']\n",
    "\n",
    "fra_words = Counter()\n",
    "for row in df['fra_list']:\n",
    "    fra_words.update(row)\n",
    "    \n",
    "eng_words = Counter()\n",
    "for row in df['eng_list']:\n",
    "    eng_words.update(row)\n",
    "\n",
    "fra_dict = {w: i for i, w in enumerate(chain.from_iterable([special_tokens, fra_words.keys()]))}\n",
    "eng_dict = {w: i for i, w in enumerate(chain.from_iterable([special_tokens, eng_words.keys()]))}\n",
    "fra_dict_rev = {v:k for k, v in fra_dict.items()}\n",
    "eng_dict_rev = {v:k for k, v in eng_dict.items()}\n",
    "\n",
    "for _ in range(len(df)):\n",
    "    fra_words.update(special_tokens)\n",
    "    eng_words.update(special_tokens)\n",
    "\n",
    "fra_weights = [1/c for c in fra_words.values()]\n",
    "eng_weights = [1/c for c in eng_words.values()]\n",
    "\n",
    "print(f\"{len(fra_dict)=}\")\n",
    "print(f\"{len(eng_dict)=}\")\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, train=True, batch_size=1, split=0.8):\n",
    "\n",
    "        df = df.sample(frac=1, ignore_index=True, random_state=0)\n",
    "        \n",
    "        row_split = int(df.shape[0] * 0.8)\n",
    "        print(f'Train split: {row_split}/{df.shape[0]}')\n",
    "        if train:\n",
    "            self.df = df[:row_split]\n",
    "        else:\n",
    "            self.df = df[row_split:]\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.df.iloc[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        return batch['fra_list'], batch['eng_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda1b61-3c0e-4a79-9d68-accb72552443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT_LENGTH=8\n",
      "BATCH_SIZE=32\n",
      "EMBED_SIZE=128\n",
      "INPUT_CLASES=24420\n",
      "OUTPUT_CLASES=12539\n",
      "\n",
      "Train split: 124213/155267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5483df00a2b41dd8c89332d505818f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Preview:', layout=Layout(height='400px', width='1000px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d09a703245a41009d73c40fc0764622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Eval:', layout=Layout(height='250px', width='1000px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a56963775443edba81000083c7ef77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c749cc8b1643ecbb2e3fad418909b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EMBED_SIZE = 128\n",
    "INPUT_CLASES = len(fra_dict)\n",
    "OUTPUT_CLASES = len(eng_dict)\n",
    "\n",
    "print(f\"{SENT_LENGTH=}\")\n",
    "print(f\"{BATCH_SIZE=}\")\n",
    "print(f\"{EMBED_SIZE=}\")\n",
    "print(f\"{INPUT_CLASES=}\")\n",
    "print(f\"{OUTPUT_CLASES=}\")\n",
    "print()\n",
    "\n",
    "train_ds = Dataset(df, train=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "t = None\n",
    "\n",
    "def assert_shape(t, dims):\n",
    "    assert len(t.shape) == len(dims), f'Expected shape {dims}, got {t.shape}'\n",
    "    for td, dd in zip(list(t.shape), dims):\n",
    "        assert td == dd, f\"Got shape: {list(t.shape)} , expected: {dims}\"\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        assert_shape(input, [BATCH_SIZE, SENT_LENGTH])\n",
    "\n",
    "        input = self.embedding(input)\n",
    "        embedded = self.dropout(input)\n",
    "        output, hidden = self.gru(embedded)\n",
    "\n",
    "        assert_shape(output, [BATCH_SIZE, SENT_LENGTH, EMBED_SIZE])\n",
    "        assert_shape(hidden, [1, BATCH_SIZE, EMBED_SIZE])\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_output, encoder_hidden, target):\n",
    "\n",
    "        assert_shape(encoder_output, [BATCH_SIZE, SENT_LENGTH, EMBED_SIZE])\n",
    "        assert_shape(encoder_hidden, [1, BATCH_SIZE, EMBED_SIZE])\n",
    "\n",
    "        if target is not None:\n",
    "            assert_shape(target, [BATCH_SIZE, SENT_LENGTH])\n",
    "\n",
    "        batch_size = encoder_output.shape[0]\n",
    "\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(SENT_LENGTH):\n",
    "            #print(i)\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target is not None:\n",
    "                # train\n",
    "                decoder_input = target[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                # eval\n",
    "                pred = decoder_output.argmax(dim=2)\n",
    "                decoder_input = pred.detach()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "\n",
    "        # Required DOWNSTREAM\n",
    "        assert_shape(decoder_outputs, [BATCH_SIZE, SENT_LENGTH, OUTPUT_CLASES])\n",
    "        assert_shape(decoder_hidden, [1, BATCH_SIZE, EMBED_SIZE])\n",
    "        \n",
    "        #decoder_output = F.log_softmax(decoder_output, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        assert_shape(input, [BATCH_SIZE, 1])\n",
    "        assert_shape(hidden, [1, BATCH_SIZE, EMBED_SIZE])\n",
    "\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class Translator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            output_size=output_size,\n",
    "            hidden_size=hidden_size,\n",
    "        )\n",
    "\n",
    "    def forward(self, input, target=None):        \n",
    "        #print(f\"{input.shape=}\")\n",
    "        output, hidden = self.encoder(input)\n",
    "        output, hidden, target = self.decoder(output, hidden, target)\n",
    "        return output, hidden\n",
    "\n",
    "if False:\n",
    "    fra_eng_translator = Translator(\n",
    "        input_size=INPUT_CLASES,\n",
    "        output_size=OUTPUT_CLASES,\n",
    "        hidden_size=EMBED_SIZE\n",
    "    )\n",
    "\n",
    "\n",
    "    lr = 0.01\n",
    "    optimizer = torch.optim.Adam(fra_eng_translator.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=1, mode='min')\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor(eng_weights), reduction='mean')\n",
    "\n",
    "def stc_to_tensor(stcs: list, word_dict):\n",
    "    t = torch.zeros([len(stcs), SENT_LENGTH], dtype=torch.int64)\n",
    "    for i, s in enumerate(stcs):\n",
    "        t[i, :len(s) + 1] = torch.tensor([word_dict[w] for w in s] + [EOS_token], dtype=torch.int64)\n",
    "    return t\n",
    "\n",
    "def eval(s):\n",
    "    fra_eng_translator.eval()\n",
    "    \n",
    "    eval_input = stc_to_tensor(s, fra_dict)\n",
    "    output, hidden = fra_eng_translator.forward(eval_input)\n",
    "    eval_out = output.argmax(dim=2)\n",
    "    #wt.value = f\"{eval_input}\"\n",
    "    wt.value = f\"{output[0].T}\"\n",
    "\n",
    "    outs = []\n",
    "    \n",
    "    for r in eval_out:\n",
    "        words = []\n",
    "        for c in r:\n",
    "            if c == EOS_token:\n",
    "                break\n",
    "            words.append(eng_dict_rev[c.item()])\n",
    "\n",
    "        outs.append(words)\n",
    "    return outs\n",
    "\n",
    "losses = []\n",
    "\n",
    "w = widgets.Textarea(\n",
    "    value='',\n",
    "    description='Preview:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='1000px', height='400px')\n",
    ")\n",
    "\n",
    "wt = widgets.Textarea(\n",
    "    value='',\n",
    "    description='Eval:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='1000px', height='250px')\n",
    ")\n",
    "\n",
    "\n",
    "display(w)\n",
    "display(wt)\n",
    "\n",
    "def train():\n",
    "\n",
    "    fra_eng_translator.train()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    pbar = tqdm(train_ds, total=len(train_ds), disable=False, leave=False)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for X, y in pbar:\n",
    "        \n",
    "        # reject because shape asserts\n",
    "        if X.shape[0] != BATCH_SIZE:\n",
    "            break\n",
    "\n",
    "        input = stc_to_tensor(X, fra_dict)\n",
    "        target = stc_to_tensor(y, eng_dict)\n",
    "\n",
    "        output, hidden = fra_eng_translator.forward(input, target)\n",
    "\n",
    "        # Required DOWNSTREAM\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy\n",
    "        output = output.movedim(1, 2)\n",
    "        assert_shape(output, [BATCH_SIZE, OUTPUT_CLASES, SENT_LENGTH])\n",
    "        assert_shape(target, [BATCH_SIZE, SENT_LENGTH])\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        evals = []\n",
    "        for i in range(1):\n",
    "            input, target = train_ds[i]\n",
    "            output = eval(input)\n",
    "            for i, t, o in zip(input.tolist(), target.tolist(), output):\n",
    "                evals.append(f\"{' '.join(i)} --- {' '.join(t)} >>> {' '.join(o)}\")\n",
    "\n",
    "        w.value = '\\n'.join(evals)\n",
    "\n",
    "        epoch_losses.append(loss.detach())\n",
    "\n",
    "        sliding_mean_loss = np.mean(epoch_losses[-1000:])\n",
    "        losses.append(sliding_mean_loss)\n",
    "        \n",
    "\n",
    "        epoch_losses.append(loss.detach())\n",
    "        pbar.set_description(f\"lr: {scheduler.get_last_lr()} Loss: {sliding_mean_loss:.10f}\")\n",
    "\n",
    "    scheduler.step(sliding_mean_loss)\n",
    "\n",
    "\n",
    "for e in tqdm(range(100), desc=\"Epoch\"):\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
